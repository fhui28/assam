% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assam.R
\name{assam}
\alias{assam}
\title{Approximate and scalable species archetype models (asSAMs)}
\usage{
assam(
  y,
  formula,
  data,
  which_spp_effects = 1,
  family,
  offset = NULL,
  trial_size = 1,
  num_archetypes,
  mesh = NULL,
  do_parallel = TRUE,
  num_cores = NULL,
  beta_selection = FALSE,
  uncertainty_quantification = TRUE,
  supply_quadapprox = NULL,
  do_assam_fit = TRUE,
  control = list(max_iter = 500, tol = 1e-04, temper_prob = 0.8, trace = FALSE,
    beta_lower = NULL, beta_upper = NULL),
  beta_selection_control = list(lambda = 1, max_iter = 100, eps = 1e-04, round_eps =
    1e-05),
  bootstrap_control = list(method = "full_bootstrap", num_boot = 100, ci_alpha = 0.05,
    seed = NULL, ci_type = "percentile")
)
}
\arguments{
\item{y}{A multivariate abundance response matrix.}

\item{formula}{An object of class "formula", which represents a symbolic description of the model matrix to be created (based on using this argument along with the \code{data} argument). \emph{Note there should be nothing on the left hand side of the "~".} Currently, smooth terms are not permitted.}

\item{data}{A data frame containing covariate information, from which the model matrix is to be created (based on this argument along with the \code{formula} argument).}

\item{which_spp_effects}{A vector identifying which columns of the model matrix induced by \code{formula} and \code{data} should be treated as species-specific effects. Default to 1, meaning only the first column i.e., the intercept, is species-specific.}

\item{family}{a description of the response distribution to be used in the model, as specified by a family function. Please see details below for more information on the distributions currently permitted.}

\item{offset}{A matrix of offset terms, of the same dimension as \code{y}.}

\item{trial_size}{Trial sizes to use for binomial distribution. This should equal to a scalar.}

\item{num_archetypes}{Number of archetypes (clusters) to assume in the asSAM.}

\item{mesh}{Output from \code{\link[sdmTMB:make_mesh]{sdmTMB::make_mesh()}}, used for adding species-specific spatial fields to the linear predictor.}

\item{do_parallel}{Should parallel computing be used to fit the asSAM. Defaults to \code{FALSE}.}

\item{num_cores}{If \code{do_parallel = TRUE}, then this argument controls the number of cores used. Defaults to \code{NULL}, in which case it is set to \code{parallel::detectCores() - 2}.}

\item{beta_selection}{Should variable selection be performed on the archetypal regression coefficients via the broken adaptive ridge \href{https://www.sciencedirect.com/science/article/pii/S0047259X17305067}{BAR} penalty? Defaults to \code{FALSE}.}

\item{uncertainty_quantification}{Should uncertainly intervals be computed via parametric bootstrap?}

\item{supply_quadapprox}{An object of class \code{assam_quadapprox}, which is (mostly likely) obtained as a consequence of running an initial fit with \code{do_assam_fit = FALSE}. Supplying this can be useful when multiple asSAMs e.g., with different values of \code{num_archetypes} are needed; see \url{https://github.com/fhui28/assam/issues/8} for an example of its usage.}

\item{do_assam_fit}{If \code{FALSE}, then the ingredients needed to construct the approximation to the log-likelihood are returned, \emph{without fitting the asSAM itself}. This can be useful when multiple asSAMs e.g., with different values of \code{num_archetypes} are needed. Otherwise, this function should be kept at its default value of \code{TRUE}.}

\item{control}{A list containing the following elements:
\describe{
\item{max_iter:}{the maximum number of iterations in the EM algorithm. Usually convergence is quite quick e.g., less than 20 iterations.}
\item{tol:}{the convergence criterion; the difference in the log-likelihood value of the asSAM from successive iterations must be smaller than this value.}
\item{temper_prob:}{in the iteration of the EM algorithm, posterior probabilities from the E-step are "tempered" or push away from the 0/1 boundary. This is often useful to get the EM algorithm moving initially.}
\item{trace:}{controls if messages are printed as part of the estimation process to reflect progress.}
\item{beta_lower:}{a vector that can be used to constrain the lower limit of the regression coefficients for each (and every) archetype, along with the species-specific effects. The length of this vector should be the same as the number of columns of the model matrix induced by \code{formula} and \code{data}. However, no checks are made on this vector, so \emph{please ensure you get the length right to ensure the correct implementation!} Defaults to \code{NULL}, in which there is no constraint.}
\item{beta_upper:}{a vector that can be used to constrain the upper limit of the regression coefficients for each (and every) archetype, along with the species-specific effects. The length of this vector should be the same as the number of columns of the model matrix induced by \code{formula} and \code{data}. However, no checks are made on this vector, so \emph{please ensure you get the length right to ensure the correct implementation!} Defaults to \code{NULL}, in which there is no constraint.}
}}

\item{beta_selection_control}{A list containing the following elements to control the broken adaptive ridge (BAR) penalty for variable selection on the archetypal regression coefficients:
\describe{
\item{lambda:}{the tuning parameter for the BAR penalty. Note the function only accepts a single value for this; if you wish to construct a regularization path for the archetypal regression coefficients, then please consider using the \code{\link[=passam]{passam()}} function instead.}
\item{max_iter:}{the maximum number of iterations in the BAR optimization part of the EM algorithm.}
\item{eps:}{the convergence criterion; the norm of the difference between all estimated parameters from successive iterations must be smaller than this value.}
\item{round_eps:}{a tolerance to round values to zero. The technically not needed as the BAR penalty will produce exactly zero estimates up to machine error, but is included anyway, but is included anyway.}
}}

\item{bootstrap_control}{A list containing the following elements to control the parametric bootstrap for uncertainty quantification:
\describe{
\item{method:}{method of parametric bootstrap to use. Two options are currently available: 1) "full_bootstrap", which is a full parametric bootstrap where new multivariate abundance responses are simulated and a new approximate likelihood function is formed each time; 2) "fast_bootstrap" which bootstraps directly/only off the approximate likelihood.
Method 1 should be more accurate, but is computationally slower and less scalable. Defaults to "full_bootstrap".}
\item{num_boot:}{the number of bootstrapped iterations to do. Defaults to 100, which can already take a long time but should be enough in a lot of settings for uncertainty quantification.}
\item{ci_alpha:}{the type-1 level for confidence interval construction. \code{100 * (1 - ci_alpha)} percent Confidence intervals are constructed.}
\item{seed:}{a seed that can be set for bootstrapping the datasets.}
\item{ci_type:}{type of confidence intervals to construct. Two options are currently available: 1) "percentile" confidence intervals based directly on the empirical quantiles of the bootstrap samples; 2) "expanded" percentile confidence intervals, which are typically slightly wider intervals that attempt to correct for a so-called "narrowness bias". Defaults to "percentile".}
}}
}
\value{
If \code{do_assam_fit = FALSE}, then a object of class \code{assam_quadapprox} is returned, which contains the ingredients needed to fit asSAMs.

Otherwise, if \code{do_assam_fit = TRUE} as is the default, then an object of class \code{assam} with the following elements (as appropriate, and not necessarily in the order below):
\item{call:}{The function call.}
\item{formula:}{Same as input argument.}
\item{family:}{Same as input argument.}
\item{num_nuisance_perspp:}{The number of "nuisance" parameters per species. For example, if \code{family = binomial()} and species-specific spatial fields are not included, then there are no nuisance parameters. If \code{family = nbinom2()} and species-specific spatial fields are included, say, then there are three nuisance parameters per species.}
\item{trial_size:}{Same as input argument.}
\item{offset:}{Same as input argument.}
\item{add_spatial:}{Were species-specific spatial fields included?}
\item{mesh:}{Same as input argument.}
\item{num_archetypes:}{Same as input argument.}
\item{uncertainty_quantification:}{Same as input argument.}
\item{spp_effects:}{Estimated species-specific effects i.e., \eqn{alpha_j}.}
\item{betas:}{Estimated matrix of archetypal regression coefficients corresponding to the model matrix created i.e., \eqn{beta_k}. The number of rows in \code{betas} is equal to the number of archetypes.}
\item{mixture_proportion:}{Estimated vector of mixture proportions corresponding to the probability of belonging to each archetype.}
\item{spp_nuisance:}{Estimated matrix of species-specific nuisance parameters e.g., the dispersion parameter in the negative binomial distribution, and dispersion and power parameters in the Tweedie distribution, and so on.}
\item{posterior_probability:}{Estimated matrix of posterior probabilities for each species belong to each archetype. The number of rows in \code{posterior_probability} is equal to the number of species.}
\item{linear_predictor:}{Estimated array of archetype-specific linear predictors for all species. The last dimension of the array corresponds to the number of archetypes.}
\item{spatial_fields:}{Predicted matrix species-specific spatial fields, if included. The spatial field prediction is developed based on the most likely archetype that the species belongs to, as judged by the posterior probabilities.}
\item{logL:}{Estimated log-likelihood value of the asSAM i.e. the value of the approximated log-likelihood function at convergence.}
\item{df:}{Number of the estimated (freely varying) parameters in the asSAM.}
\item{linear_predictor:}{Estimated array of archetype-specific linear predictors. The last dimension of the array corresponds to the number of archetypes.}
\item{control:}{Same as input argument.}
\item{bootstrap_control:}{Same as input argument.}
\item{beta_selection_control:}{Same as input argument.}
\item{confidence_intervals:}{A list of estimated parametric bootstrap confidence intervals for all the parameters in the asSAM, with each element in the list corresponding to one of the parameters e.g., the species-specific effects, the mixture proportions, and so on.}
\item{bootstrap_paramters:}{A matrix of estimated (untransformed) parameters from the parametric bootstrap. \emph{This output can be safely ignored by most users}, but those curious, it is used to uncertainty quantification for downstream predictions, say.}
\item{bootstrap_posterior_probability:}{An array of estimated posterior probabilities from the parametric bootstrap. \emph{This output can be safely ignored by most users}, but those curious, it is used to uncertainty quantification for downstream predictions, say.}
\item{sdmTMB_fits}{A list of the set of stacked species distribution models fitted using \code{\link[sdmTMB:sdmTMB]{sdmTMB::sdmTMB()}}. \emph{This output can be safely ignored by most users}.}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

Fits approximate and scalable species archetype modeling (asSAMs) for model-based clustering of species based on their environmental response, into a small number of so-called archetypal responses. The basic idea is take the log-likelihood function of SAM, and then construct an approximation of this which (hopefully) is more scalable in both the number of sites and species.
}
\details{
For the purposes of the package, the SAM is characterized by the following mean regression model: for observational unit \eqn{i=1,\ldots,N} and species \eqn{j=1,\ldots,M}, conditional on the species belong to archetype \eqn{k},

\deqn{g(\mu_{ij}) = \eta_{ij} = u_i^\top\alpha_j + x_i^\top\beta_k,}

where \eqn{g(.)} is a known link function, \eqn{u_i^\top\alpha_j} corresponds to a component that is to kept species-specific e.g., species-specific intercept, \eqn{x_i^\top\beta_k}  denotes the component corresponding to effect of archetypal response \eqn{k}. Additionally, species-specific spatial fields can be included in the linear predictor e.g., to account for residual spatial correlation above and beyond that explained by the archetypal responses. Conditional on the mean model above, the \eqn{y_{ij}} are assumed to be come from some response distribution using the additional dispersion and power parameters as appropriate. We refer the reader to \href{https://doi.org/10.1016/j.ecolmodel.2010.11.030}{Dunstan et al., (2011)}, \href{https://doi.org/10.1890/12-1322.1}{Hui et al., (2013)}, \href{https://doi.org/10.1007/s13253-013-0146-x}{Dunstan et al., (2013)}, and \href{https://github.com/skiptoniam/ecomix}{Skipton Woolley's ecomix package} for more details about the formulations of SAMs.

The broad goal of this package is to construct a way of fitting SAMs that are, although approximate, more scalable in the number of sites and species (though not necessarily faster), hence the name asSAMs. We refer to the corresponding manuscript (in preparation) for details, but to summarize, asSAMs are formed by constructing an approximate likelihood function for a SAM based on using ingredients (i.e., point estimates and the associated observed information matrix) from stacked species distribution models (which are fitted initially in parallel), and then building what is essentially a finite mixture of multivariate Gaussian distributions from this. This is then maximized using an EM algorithm, which can be done scalably and very quickly.

For uncertainty quantification, two forms of parametric bootstrap are available along the lines of Section 2.16.2 in \href{https://www.wiley.com/en-us/Finite+Mixture+Models-p-9780471654063}{McLachlan and Peel (2004)}.

Common lower and upper limit constraints can be placed on the \eqn{\beta_k} for each (and every) archetype.

Variable selection on the elements of \eqn{\beta_k} can be performed via the broken adaptive ridge \href{https://www.sciencedirect.com/science/article/pii/S0047259X17305067}{BAR} penalty, via the \code{beta_selection} and \code{beta_selection_control} arguments. The BAR penalty can be interpreted as a kind of approximation to the \eqn{L_0} penalty, and encourages sparsity in the archetypal regression coefficients e.g., to uncover what covariates are informative for each of the archetypal responses. Note the function is set up to only accept a single value for the tuning parameter: to construct a full regularization path for the archetypal regression coefficients given the BAR penalty and/or to peform selection on the mixture proportions and thus select the number of archetypes to include in a asSAM, please consider using the \code{\link[=passam]{passam()}} function instead. Note, in the case model selection is performed, bootstrap uncertainty quantification is performed \emph{conditional on selected model}.

\subsection{Distributions}{
Currently the following response distributions are permitted:
\describe{
\item{\code{Beta()}:}{Beta distribution using a logit link. The corresponding mean-variance relationship is given by \eqn{V = \mu(1-\mu)/(1+\phi)} where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{binomial()}:}{Binomial distribution. The corresponding mean-variance relationship is given by \eqn{V = N_{trial}\mu(1-\mu)} where \eqn{\mu} denotes the mean and \eqn{N_{trial}} is the trial size.}
\item{\code{Gamma()}:}{Gamma distribution, noting only the log link is permitted. The corresponding mean-variance relationship is given by \eqn{V = \phi\mu^2} where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{gaussian()}:}{Gaussian or normal distribution. The corresponding mean-variance relationship is given by \eqn{V = \phi^2}, where \eqn{\phi} is the standard deviation.}
\item{\code{poisson()}:}{Poisson distribution. The corresponding mean-variance relationship is given by \eqn{V = \mu} where \eqn{\mu} denotes the mean.}
\item{\code{nbinom2()}:}{Negative binomial distribution using a log link. The corresponding mean-variance relationship is given by \eqn{V = \mu + \mu^2/\phi} where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{tweedie()}:}{Tweedie distribution using a log link. The corresponding mean-variance relationship is given by \eqn{V = \phi\mu^{\rho}} where \eqn{\mu} denotes the mean, \eqn{\phi} is the dispersion parameter, and \eqn{\rho} is the power parameter.}
}
}
}
\section{A note on parallelization}{

The scalability of asSAMs relies on being able to deploy \code{\link[sdmTMB:sdmTMB]{sdmTMB::sdmTMB()}} is an efficient and fully optimized manner. Along these lines, please see \href{https://github.com/pbs-assess/sdmTMB/issues/368}{using sdmTMB in parallel} and \href{https://gist.github.com/seananderson/08a51e296a854f227a908ddd365fb9c1}{using OpenBLAS} and references therein for some tips to ensure things on your machine are more optimized. Thanks to Sean Anderson for this advice!
}

\examples{
\dontrun{
##----------------------
# Example 1: Generate some multivariate abundance (count) data from a SAM
##----------------------
library(tidyverse)
library(mvtnorm)
library(GGally)
library(doParallel)

set.seed(022025)

num_X <- 10
num_units <- 1000
num_spp <- 100
num_archetype <- 5
H <- outer(1:num_X, 1:num_X, "-")
H <- 0.5^abs(H)
covariate_dat <- rmvnorm(num_units, sigma = H) \%>\% 
    as.data.frame \%>\% 
    rename_with(., .fn = function(x) paste0("covariate", x))
rm(H)

true_betas <- runif(num_archetype * num_X, -1, 1) \%>\% matrix(nrow = num_archetype)
true_spp_effects <- matrix(runif(num_spp, -2, 0), ncol = 1)
true_dispparam <- 1/runif(num_spp, 1, 5) 
true_powerparam <- runif(num_spp, 1.4, 1.8)
true_mixprop <- c(0.2, 0.2, 0.3, 0.15, 0.15)
 
simdat <- create_samlife(family = nbinom2(), 
formula = paste("~ ", paste0(colnames(covariate_dat), collapse = "+")) \%>\% as.formula, 
data = covariate_dat, 
betas = true_betas, 
spp_effects = true_spp_effects, 
spp_dispparam = true_dispparam, 
spp_powerparam = true_powerparam, 
mixture_proportion = true_mixprop,
seed = 022025)

 
## Fit asSAM and assess results 
#' **Most users should start here**
samfit <- assam(y = simdat$y,
formula = paste("~ ", paste0(colnames(covariate_dat), collapse = "+")) \%>\% as.formula,
data = covariate_dat,
family = nbinom2(),
num_archetypes = num_archetype,
num_cores = detectCores() - 2)

 
plot(true_spp_effects, samfit$spp_effects); abline(0,1)
plot(true_dispparam, samfit$spp_nuisance$dispersion, log = "xy"); abline(0,1)
#' Note estimates for the archetypal responses and mixture proportions from (as)SAMs should be 
#' close to the corresponding true values, *up to a reordering* of the mixture component
#' s/archetypes (since the order is essentially arbitrary)
rbind(true_betas, samfit$betas) \%>\% 
t \%>\% 
as.data.frame \%>\%
GGally::ggpairs(.)
table(simdat$archetype_label, apply(samfit$posterior_probability, 1, which.max))

 
## Demonstrating basic use of functions for asSAM 
samfit
summary(samfit)

fitted(samfit)
 
simulate(samfit, data = covariate_dat)

residuals(samfit, type = "dunnsmyth")
 
#' Basic residual analysis
plot(samfit, transform_fitted_values = TRUE, envelope = FALSE)
 
#' Archetype-level predictions
predict(samfit, newdata = covariate_dat, type = "archetype", se_fit = TRUE) 

#' Species-level predictions
predict(samfit, newdata = covariate_dat, type = "species_max", num_cores = 8, se_fit = TRUE) 
 
 
 
##----------------------
# Example 2: Demonstrating variable selection on the archetypal regression coefficients
# Generate some multivariate abundance (non-negative continuous) data from a sparse SAM
# Note only a single tuning parameter is used below; please see the [passam()] for 
# constructing a proper regularization path, as well as to perform selection on the 
mixing proportions i.e., choose the number of archetypes. 
##----------------------
true_betas <- runif(num_archetype * num_X, -1, 1) \%>\% matrix(nrow = num_archetype)
true_betas[which(abs(true_betas) < 0.4)] <- 0 # Making archetypal coefficients sparse
true_betas


simdat <- create_samlife(family = tweedie(),
formula = paste("~ ", paste0(colnames(covariate_dat), collapse = "+")) \%>\% as.formula,
data = covariate_dat,
betas = true_betas,
spp_effects = true_spp_effects,
spp_dispparam = true_dispparam,
spp_powerparam = true_powerparam,
mixture_proportion = true_mixprop,
seed = 022025)


## Fit asSAM and assess results 
#' **Most users should start here**
samfit_select <- assam(y = simdat$y,
formula = paste("~ ", paste0(colnames(covariate_dat), collapse = "+")) \%>\% as.formula,
data = covariate_dat,
family = tweedie(),
beta_selection = TRUE,
num_archetypes = num_archetype,
beta_selection_control = list(lambda = 0.1), # Note this an arbitrary choice!
bootstrap_control = list(num_boot = 10), 
num_cores = detectCores() - 2)

samfit_select
samfit_select$betas
true_betas


plot(true_spp_effects, samfit_select$spp_effects); abline(0,1)
plot(true_dispparam, samfit_select$spp_nuisance$dispersion, log = "xy"); abline(0,1)
plot(true_powerparam, samfit_select$spp_nuisance$power, log = "xy"); abline(0,1)
#' Note estimates for the archetypal responses and mixture proportions from (as)SAMs should be 
#' close to the corresponding true values, *up to a reordering* of the mixture component
#' s/archetypes (since the order is essentially arbitrary)
rbind(true_betas, samfit_select$betas) \%>\% 
t \%>\% 
as.data.frame \%>\%
GGally::ggpairs(.)
table(simdat$archetype_label, apply(samfit_select$posterior_probability, 1, which.max))


## Demonstrating basic use of functions for asSAM 
summary(samfit_select)

fitted(samfit_select)
 
simulate(samfit_select, data = covariate_dat)

residuals(samfit, type = "dunnsmyth")
 
#' Basic residual analysis
plot(samfit_select, transform_fitted_values = TRUE, envelope = FALSE)
 
#' Archetype-level predictions
predict(samfit_select, newdata = covariate_dat, type = "archetype", se_fit = TRUE) 

#' Species-level predictions
predict(samfit_select, newdata = covariate_dat, type = "species_max", num_cores = 8, se_fit = TRUE) 
}



}
\author{
Francis K.C. Hui \href{mailto:fhui28@gmail.com}{fhui28@gmail.com}
}
